{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "rcParams['figure.figsize'] = 10, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = Path('/media/klaus/Ondrag/dev/datasets/300VW_Dataset_2015_12_14')\n",
    "temp_path = Path('/media/klaus/Ondrag/dev/datasets/300VW_Dataset_2015_12_14_temp')\n",
    "output_path = Path('/media/klaus/Ondrag/dev/datasets/300VW_Dataset_2015_12_14_processed')\n",
    "n_videos = 114\n",
    "n_points = 68\n",
    "padding = 0\n",
    "expand_ratio = 0.5\n",
    "image_quality = 100\n",
    "output_height, output_width = 128, 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_videos = sorted([p for p in input_path.iterdir() if p.is_dir()])\n",
    "assert len(all_videos) == n_videos\n",
    "n_images_per_video = [\n",
    "    len(list((video_path / 'annot').glob('*.pts')))\n",
    "    for video_path in tqdm(all_videos, desc='video')\n",
    "]\n",
    "n_images = sum(n_images_per_video)\n",
    "\n",
    "print(f'n images: {n_images}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for video_input_path, n_images_in_video in tqdm(list(zip(all_videos, n_images_per_video)), \n",
    "                                                desc='video'):\n",
    "    frames_output_dir = temp_path / video_input_path.stem / 'images'\n",
    "    if frames_output_dir.exists() and len(list(frames_output_dir.iterdir())) == n_images_in_video:\n",
    "        continue\n",
    "    \n",
    "    frames_output_dir.mkdir(exist_ok=True, parents=True)\n",
    "    avi_path = video_input_path / 'vid.avi'\n",
    "    video = cv2.VideoCapture(str(avi_path))\n",
    "    \n",
    "    counter = 1\n",
    "    success, image = video.read()\n",
    "    while success == 1:\n",
    "        frame_output_path = frames_output_dir / f'{counter:06d}.jpg'\n",
    "        cv2.imwrite(str(frame_output_path), image, [int(cv2.IMWRITE_JPEG_QUALITY), image_quality])\n",
    "        counter += 1\n",
    "        success, image = video.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def load_pts_file(file_path: Path) -> np.ndarray:\n",
    "    with open(str(file_path), 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        \n",
    "    assert lines[0].strip().startswith('version: 1'), str(file_path)\n",
    "    assert lines[1] == f'n_points: {n_points}\\n', str(file_path)\n",
    "    \n",
    "    lines = [l.strip() for l in lines]\n",
    "    # remove\n",
    "    # version: 1\n",
    "    # n_points: 68\n",
    "    # {\n",
    "    lines = lines[3:]\n",
    "    # remove\n",
    "    # }\n",
    "    lines = lines[:-1]\n",
    "    points = [[float(x) for x in p.split()]\n",
    "              for p in lines]\n",
    "    points = np.asarray(points)\n",
    "    assert points.shape == (n_points, 2)\n",
    "    return points\n",
    "\n",
    "\n",
    "def points_to_box(points: np.ndarray, image_size: Tuple[int, int]) -> Tuple[float, float, float, float]:\n",
    "    x1, y1, x2, y2 = [points[:, 0].min(), points[:, 1].min(), points[:, 0].max(), points[:, 1].max()]\n",
    "    x1, y1 = [t - padding for t in (x1, y1)]\n",
    "    x2, y2 = [t + padding for t in (x2, y2)]\n",
    "    box_height, box_width = y2 - y1 + 1, x2 - x1 + 1\n",
    "    assert box_height > 1 and box_width > 1\n",
    "    \n",
    "    if expand_ratio is not None:\n",
    "        box_height *= expand_ratio\n",
    "        box_width *= expand_ratio\n",
    "        x1, y1 = [math.floor(t - s) for t, s in zip((x1, y1), (box_width, box_height))]\n",
    "        x2, y2 = [math.ceil(t + s) for t, s in zip((x2, y2), (box_width, box_height))]\n",
    "    \n",
    "    image_height, image_width, _ = image_size\n",
    "    # landmarks can be out of image, but that's okay, we'll still export them.\n",
    "    x1, y1 = [t if t >= 0 else 0 for t in (x1, y1)]\n",
    "    x2, y2 = [t if t < m else m for t, m in zip((x2, y2), (image_width, image_height))]\n",
    "    assert x1 <= x2 and y1 <= y2\n",
    "    \n",
    "    return x1, y1, x2, y2\n",
    "\n",
    "\n",
    "def extract(image: np.ndarray, box: Tuple[float, float, float, float]) -> np.ndarray:\n",
    "    x1, y1, x2, y2 = box\n",
    "    extraction = image[y1:y2+1, x1:x2+1, ...]\n",
    "    return extraction\n",
    "\n",
    "\n",
    "def offset_points(points: np.ndarray, box: Tuple[float, float, float, float]) -> np.ndarray:\n",
    "    x1, y1, x2, y2 = box\n",
    "    points = copy(points)\n",
    "    points[:, 0] -= x1\n",
    "    points[:, 1] -= y1\n",
    "    return points\n",
    "\n",
    "\n",
    "def rescale_image(image: np.ndarray) -> np.ndarray:\n",
    "    _, _, n_channels = image.shape\n",
    "    image = cv2.resize(image, dsize=(output_width, output_height), interpolation=cv2.INTER_CUBIC)\n",
    "    assert image.shape == (output_height, output_width, n_channels)    \n",
    "    return image\n",
    "\n",
    "\n",
    "def rescale_points(points: np.ndarray, image_shape: Tuple[int, int, int]) -> np.ndarray:\n",
    "    height, width, n_channels = image_shape    \n",
    "    points = copy(points)\n",
    "    height_factor = 1 / height * output_height\n",
    "    width_factor = 1 / width * output_width\n",
    "    points[:, 0] *= width_factor\n",
    "    points[:, 1] *= height_factor    \n",
    "    return points\n",
    "\n",
    "\n",
    "def plot(image, points: np.ndarray = None, box: Tuple[int, int, int, int] = None) -> None:\n",
    "    plt.figure()\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "\n",
    "    if points is not None:\n",
    "        cmap = plt.get_cmap('gnuplot')\n",
    "        colors = [cmap(i) for i in np.linspace(0, 1, len(points))]\n",
    "        for index, c in zip(range(len(points)), colors):\n",
    "            plt.plot([points[index, 0]], [points[index, 1]], 'x', color=c)\n",
    "    \n",
    "    if box is not None:\n",
    "        x1, y1, x2, y2 = box\n",
    "        rect = patches.Rectangle((x1, y1), x2 - x1, y2 - y1, \n",
    "                                 linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax = plt.gca()\n",
    "        ax.add_patch(rect)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize(video_id: str, frame_id: str) -> None:\n",
    "    annotation_input_path = input_path / video_id / 'annot' / f'{frame_id}.pts'\n",
    "    frame_input_path = temp_path / video_id / 'images' / f'{frame_id}.jpg'\n",
    "    image = cv2.imread(str(frame_input_path))\n",
    "    image_points = load_pts_file(str(annotation_input_path))\n",
    "    image_box = points_to_box(image_points, image.shape)\n",
    "    \n",
    "    extraction = extract(image, image_box)\n",
    "    extraction_points = offset_points(image_points, image_box)\n",
    "    \n",
    "    output = rescale_image(extraction)\n",
    "    output_points = rescale_points(extraction_points, extraction.shape)\n",
    "    \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    plot(image)\n",
    "    plot(image, image_points)\n",
    "    plot(image, image_points, image_box)\n",
    "    extraction = cv2.cvtColor(extraction, cv2.COLOR_BGR2RGB)\n",
    "    plot(extraction)\n",
    "    plot(extraction, extraction_points)\n",
    "    output = cv2.cvtColor(output, cv2.COLOR_BGR2RGB)\n",
    "    plot(output, output_points)\n",
    "    \n",
    "\n",
    "visualize('001', '000001')\n",
    "for video_input_path in tqdm(all_videos, desc='video'):\n",
    "    video_output_path = output_path / video_input_path.stem\n",
    "    annotations_output_dir = video_output_path / 'annotations'\n",
    "    annotations_output_dir.mkdir(exist_ok=True, parents=True)\n",
    "    frames_output_dir = video_output_path / 'images'\n",
    "    frames_output_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    for annotation_input_path in tqdm(sorted(list((video_input_path / 'annot').glob('*.pts'))),\n",
    "                                      desc='frame', leave=False):\n",
    "        frame_output_path = frames_output_dir / f'{annotation_input_path.stem}.jpg'\n",
    "        annotation_output_path = annotations_output_dir / f'{annotation_input_path.stem}.txt'\n",
    "        if frame_output_path.exists() and annotation_output_path.exists():\n",
    "            continue\n",
    "        \n",
    "        frame_input_path = temp_path / video_input_path.stem / 'images' / f'{annotation_input_path.stem}.jpg'\n",
    "        image = cv2.imread(str(frame_input_path))\n",
    "        image_points = load_pts_file(str(annotation_input_path))\n",
    "        image_box = points_to_box(image_points, image.shape)\n",
    "        \n",
    "        extraction = extract(image, image_box)\n",
    "        extraction_points = offset_points(image_points, image_box)\n",
    "        \n",
    "        if not frame_output_path.exists():\n",
    "            output = rescale_image(extraction)\n",
    "            cv2.imwrite(str(frame_output_path), output, [int(cv2.IMWRITE_JPEG_QUALITY), image_quality])\n",
    "        \n",
    "        if not annotation_output_path.exists():\n",
    "            output_points = rescale_points(extraction_points, extraction.shape)\n",
    "            np.savetxt(str(annotation_output_path), output_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
